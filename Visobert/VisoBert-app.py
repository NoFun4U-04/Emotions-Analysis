import streamlit as st
import os

import torch
import torch
import torch.nn as nn
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from transformers import AutoTokenizer, AutoModel
from preprocessing import clean_doc
import warnings
warnings.filterwarnings('ignore')





st.set_page_config(
    page_title="ViSoBERT Emotion Recognition",
    page_icon="üòä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }

    .emotion-card {
        background: #f8f9ff;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 0.5rem 0;
    }

    .prediction-box {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 10px;
        text-align: center;
        margin: 1rem 0;
    }

    .metrics-container {
        background: #ffffff;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }

    .sidebar-info {
        background: #f0f2f6;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
        color: black;
    }
</style>
""", unsafe_allow_html=True)

# ==================== MODEL DEFINITIONS ====================
class ViSoBERTEmotionClassifier(nn.Module):
    def __init__(self, model_name, num_classes=7, dropout_rate=0.3):
        super(ViSoBERTEmotionClassifier, self).__init__()

        # Load ViSoBERT model
        self.visobert = AutoModel.from_pretrained(model_name)

        # Classifier layers
        self.dropout = nn.Dropout(dropout_rate)
        self.classifier = nn.Sequential(
            nn.Linear(self.visobert.config.hidden_size, 512),
            nn.ReLU(),
            nn.Dropout(dropout_rate),
            nn.Linear(512, num_classes)
        )

    def forward(self, input_ids, attention_mask):
        outputs = self.visobert(
            input_ids=input_ids,
            attention_mask=attention_mask
        )

        pooled_output = outputs.pooler_output
        output = self.dropout(pooled_output)
        logits = self.classifier(output)

        return logits

# ==================== CONSTANTS ====================
emotion_labels = {
    0: "Vui v·∫ª",
    1: "Bu·ªìn b√£",
    2: "T·ª©c gi·∫≠n",
    3: "S·ª£ h√£i",
    4: "Ng·∫°c nhi√™n",
    5: "Kinh t·ªüm",
    6: "Kh√°c"
}

emotion_colors = {
    "Vui v·∫ª": "#FFD700",
    "Bu·ªìn b√£": "#4169E1",
    "T·ª©c gi·∫≠n": "#DC143C",
    "S·ª£ h√£i": "#800080",
    "Ng·∫°c nhi√™n": "#FF8C00",
    "Kinh t·ªüm": "#228B22",
    "Kh√°c": "#808080"
}

emotion_emojis = {
    "Vui v·∫ª": "üòä",
    "Bu·ªìn b√£": "üò¢",
    "T·ª©c gi·∫≠n": "üò†",
    "S·ª£ h√£i": "üò®",
    "Ng·∫°c nhi√™n": "üò≤",
    "Kinh t·ªüm": "ü§¢",
    "Kh√°c": "üòê"
}

# ==================== CACHING FUNCTIONS ====================
@st.cache_resource
def load_model_and_tokenizer():
    """Load model v√† tokenizer v·ªõi caching"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        model_name = "uitnlp/visobert"

        # Load tokenizer
        tokenizer = AutoTokenizer.from_pretrained(model_name)

        # Load model
        model = ViSoBERTEmotionClassifier(model_name, num_classes=7)

        # Load trained weights
        model_path = '/content/best_visobert_emotion_model.pth'
        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint)
        model.to(device)
        model.eval()

        return model, tokenizer, device, checkpoint
    except Exception as e:
        st.error(f"L·ªói khi load model: {e}")
        return None, None, None, None

# ==================== PREDICTION FUNCTIONS ====================
def predict_emotion(model, tokenizer, device, text, max_length=256):
    """D·ª± ƒëo√°n c·∫£m x√∫c cho vƒÉn b·∫£n"""
    try:
        # Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n
        text = clean_doc(text)  

        # Tokenization
        encoding = tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=max_length,
            return_tensors='pt'
        )

        input_ids = encoding['input_ids'].to(device)
        attention_mask = encoding['attention_mask'].to(device)

        with torch.no_grad():
            logits = model(input_ids, attention_mask)
            probabilities = torch.softmax(logits, dim=1)
            predicted_class = torch.argmax(logits, dim=1).item()
            confidence = probabilities[0][predicted_class].item()

        return {
            'emotion': emotion_labels[predicted_class],
            'confidence': confidence,
            'probabilities': {emotion_labels[i]: prob.item()
                             for i, prob in enumerate(probabilities[0])}
        }
    except Exception as e:
        st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")
        return None

def create_probability_chart(probabilities):
    """T·∫°o bi·ªÉu ƒë·ªì x√°c su·∫•t cho c√°c c·∫£m x√∫c"""
    emotions = list(probabilities.keys())
    probs = list(probabilities.values())
    colors = [emotion_colors[emotion] for emotion in emotions]

    fig = px.bar(
        x=emotions,
        y=probs,
        color=emotions,
        color_discrete_map=emotion_colors,
        title="Ph√¢n b·ªë x√°c su·∫•t c√°c c·∫£m x√∫c",
        labels={'x': 'C·∫£m x√∫c', 'y': 'X√°c su·∫•t'}
    )

    fig.update_layout(
        showlegend=False,
        height=400,
        xaxis_tickangle=-45
    )

    return fig


# ==================== MAIN APP ====================
def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>ü§ñ ViSoBERT Emotion Recognition</h1>
        <p>Ph√¢n t√≠ch c·∫£m x√∫c vƒÉn b·∫£n ti·∫øng Vi·ªát v·ªõi m√¥ h√¨nh ViSoBERT</p>
    </div>
    """, unsafe_allow_html=True)

    # Load model
    with st.spinner("ƒêang t·∫£i model..."):
        model, tokenizer, device, checkpoint = load_model_and_tokenizer()

    if model is None:
        st.error("Kh√¥ng th·ªÉ t·∫£i model. Vui l√≤ng ki·ªÉm tra ƒë∆∞·ªùng d·∫´n file model.")
        return

    # Sidebar - Model Info
    with st.sidebar:
        st.markdown("### üìä Th√¥ng tin Model")
        if checkpoint:
            st.markdown(f"""
            <div class="sidebar-info">
                <strong>Model:</strong> ViSoBERT
                <strong>Loss:</strong> Focal Loss
            </div>
            """, unsafe_allow_html=True)

        st.markdown("### üéØ C√°c lo·∫°i c·∫£m x√∫c")
        for emotion, emoji in emotion_emojis.items():
            st.markdown(f"{emoji} **{emotion}**")

    # Main content
    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("### üìù Nh·∫≠p vƒÉn b·∫£n ƒë·ªÉ ph√¢n t√≠ch")

        # Text input methods
        input_method = st.radio(
            "Ch·ªçn c√°ch nh·∫≠p:",
            ["Nh·∫≠p tr·ª±c ti·∫øp", "Upload file (CSV/Excel)"]
        )

        text_input = ""
        batch_analysis = False
        df_to_analyze = None
        selected_column = None

        if input_method == "Nh·∫≠p tr·ª±c ti·∫øp":
            text_input = st.text_area(
                "VƒÉn b·∫£n:",
                height=150,
                placeholder="V√≠ d·ª•: H√¥m nay t√¥i r·∫•t vui v√¨ ƒë∆∞·ª£c g·∫∑p b·∫°n b√®...",
                help="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát ƒë·ªÉ ph√¢n t√≠ch c·∫£m x√∫c"
            )
        else:
            st.markdown("#### üìÇ Upload file d·ªØ li·ªáu")
            uploaded_file = st.file_uploader(
                "Ch·ªçn file CSV ho·∫∑c Excel",
                type=["csv", "xlsx", "xls"],
                help="File ph·∫£i ch·ª©a c·ªôt 'text' ho·∫∑c t∆∞∆°ng t·ª± v·ªõi n·ªôi dung vƒÉn b·∫£n"
            )

            if uploaded_file is not None:
                try:
                    # ƒê·ªçc file
                    if uploaded_file.name.endswith(".csv"):
                        df = pd.read_csv(uploaded_file)
                    else:
                        df = pd.read_excel(uploaded_file)

                    st.success(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng file v·ªõi {len(df)} d√≤ng d·ªØ li·ªáu")

                    # Hi·ªÉn th·ªã preview
                    with st.expander("üëÄ Xem tr∆∞·ªõc d·ªØ li·ªáu", expanded=False):
                        st.dataframe(df.head(10))

                    # Ch·ªçn c·ªôt ch·ª©a text
                    text_columns = [col for col in df.columns if df[col].dtype == 'object']

                    if text_columns:
                        selected_column = st.selectbox(
                            "Ch·ªçn c·ªôt ch·ª©a vƒÉn b·∫£n:",
                            text_columns,
                            help="Ch·ªçn c·ªôt ch·ª©a n·ªôi dung vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch"
                        )

                        # Ch·ªçn ch·∫ø ƒë·ªô ph√¢n t√≠ch
                        analysis_mode = st.radio(
                            "Ch·ªçn ch·∫ø ƒë·ªô ph√¢n t√≠ch:",
                            ["Ph√¢n t√≠ch t·ª´ng c√¢u", "Ph√¢n t√≠ch to√†n b·ªô file"],
                            help="Ch·ªçn ph√¢n t√≠ch t·ª´ng c√¢u ho·∫∑c ph√¢n t√≠ch t·∫•t c·∫£ d·ªØ li·ªáu trong file"
                        )

                        if selected_column in df.columns:
                            # Lo·∫°i b·ªè c√°c d√≤ng tr·ªëng
                            valid_texts = df[selected_column].dropna()

                            if len(valid_texts) > 0:
                                if analysis_mode == "Ph√¢n t√≠ch t·ª´ng c√¢u":
                                    # Ch·∫ø ƒë·ªô ph√¢n t√≠ch ƒë∆°n l·∫ª
                                    selected_index = st.selectbox(
                                        "Ch·ªçn c√¢u ƒë·ªÉ ph√¢n t√≠ch:",
                                        range(len(valid_texts)),
                                        format_func=lambda x: f"D√≤ng {x+1}: {str(valid_texts.iloc[x])[:100]}{'...' if len(str(valid_texts.iloc[x])) > 100 else ''}"
                                    )

                                    selected_text = str(valid_texts.iloc[selected_index])
                                    text_input = st.text_area(
                                        "VƒÉn b·∫£n ƒë∆∞·ª£c ch·ªçn (c√≥ th·ªÉ ch·ªânh s·ª≠a):",
                                        value=selected_text,
                                        height=100
                                    )
                                else:
                                    # Ch·∫ø ƒë·ªô ph√¢n t√≠ch batch
                                    batch_analysis = True
                                    df_to_analyze = df[df[selected_column].notna()].copy()

                                    st.info(f"üîÑ S·∫Ω ph√¢n t√≠ch {len(df_to_analyze)} vƒÉn b·∫£n trong file")

                                    # Hi·ªÉn th·ªã sample
                                    with st.expander("üìù Xem m·∫´u d·ªØ li·ªáu s·∫Ω ph√¢n t√≠ch"):
                                        sample_df = df_to_analyze[[selected_column]].head(5)
                                        st.dataframe(sample_df)
                            else:
                                st.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu vƒÉn b·∫£n h·ª£p l·ªá trong c·ªôt ƒë√£ ch·ªçn.")
                    else:
                        st.error("‚ùå File kh√¥ng ch·ª©a c·ªôt vƒÉn b·∫£n. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë·ªãnh d·∫°ng file.")

                except Exception as e:
                    st.error(f"‚ùå L·ªói khi ƒë·ªçc file: {str(e)}")
                    st.info("üí° ƒê·∫£m b·∫£o file c√≥ ƒë·ªãnh d·∫°ng ƒë√∫ng v√† ch·ª©a d·ªØ li·ªáu vƒÉn b·∫£n.")
            else:
                st.info("üì§ Vui l√≤ng ch·ªçn file ƒë·ªÉ t·∫£i l√™n")

        # Predict button
        st.markdown("---")
        predict_button = st.button(
            "üéØ Ph√¢n t√≠ch c·∫£m x√∫c",
            type="primary",
            use_container_width=True,
            disabled=(not text_input.strip() and not batch_analysis)
        )

        # Results section
        if predict_button and (text_input.strip() or batch_analysis):
            if batch_analysis and df_to_analyze is not None:
                # Batch analysis
                st.markdown("### üîÑ Ph√¢n t√≠ch to√†n b·ªô file")

                # Progress bar
                progress_bar = st.progress(0)
                status_text = st.empty()

                results = []
                total_texts = len(df_to_analyze)

                for idx, row in df_to_analyze.iterrows():
                    text = str(row[selected_column])
                    if text.strip():
                        status_text.text(f'ƒêang ph√¢n t√≠ch vƒÉn b·∫£n {len(results)+1}/{total_texts}...')
                        result = predict_emotion(model, tokenizer, device, text)

                        if result:
                            results.append({
                                'index': idx,
                                'text': text,
                                'emotion': result['emotion'],
                                'confidence': result['confidence'],
                                'probabilities': result['probabilities']
                            })

                        progress_bar.progress((len(results)) / total_texts)

                status_text.text('‚úÖ Ho√†n th√†nh ph√¢n t√≠ch!')
                progress_bar.progress(1.0)

                if results:
                    # Create results dataframe
                    results_df = pd.DataFrame([
                        {
                            'STT': i+1,
                            'VƒÉn b·∫£n': r['text'][:100] + '...' if len(r['text']) > 100 else r['text'],
                            'C·∫£m x√∫c': emotion_emojis[r['emotion']] + ' ' + r['emotion'],
                            'ƒê·ªô tin c·∫≠y': f"{r['confidence']:.2%}"
                        }
                        for i, r in enumerate(results)
                    ])

                    # Display results table
                    st.markdown("#### üìä K·∫øt qu·∫£ ph√¢n t√≠ch")
                    st.dataframe(results_df, use_container_width=True, hide_index=True)

                    # Statistics
                    emotion_counts = {}
                    for r in results:
                        emotion = r['emotion']
                        emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

                    # Emotion distribution chart
                    st.markdown("#### üìà Ph√¢n b·ªë c·∫£m x√∫c")
                    col_chart1, col_chart2 = st.columns(2)

                    with col_chart1:
                        # Pie chart
                        fig_pie = px.pie(
                            values=list(emotion_counts.values()),
                            names=[emotion_emojis[e] + ' ' + e for e in emotion_counts.keys()],
                            title="T·ª∑ l·ªá c√°c c·∫£m x√∫c",
                            color_discrete_map={emotion_emojis[e] + ' ' + e: emotion_colors[e] for e in emotion_counts.keys()}
                        )
                        st.plotly_chart(fig_pie, use_container_width=True)

                    with col_chart2:
                        # Bar chart
                        emotions_for_bar = [emotion_emojis[e] + ' ' + e for e in emotion_counts.keys()]
                        fig_bar = px.bar(
                            x=emotions_for_bar,
                            y=list(emotion_counts.values()),
                            title="S·ªë l∆∞·ª£ng theo c·∫£m x√∫c",
                            color=emotions_for_bar,
                            color_discrete_map={emotion_emojis[e] + ' ' + e: emotion_colors[e] for e in emotion_counts.keys()}
                        )
                        fig_bar.update_layout(showlegend=False, xaxis_tickangle=-45)
                        st.plotly_chart(fig_bar, use_container_width=True)

                    # Summary statistics
                    st.markdown("#### üìù Th·ªëng k√™ t·ªïng quan")
                    col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

                    with col_stat1:
                        st.metric("T·ªïng s·ªë vƒÉn b·∫£n", len(results))
                    with col_stat2:
                        avg_confidence = np.mean([r['confidence'] for r in results])
                        st.metric("ƒê·ªô tin c·∫≠y TB", f"{avg_confidence:.2%}")
                    with col_stat3:
                        most_common = max(emotion_counts.items(), key=lambda x: x[1])
                        st.metric("C·∫£m x√∫c ph·ªï bi·∫øn nh·∫•t", f"{emotion_emojis[most_common[0]]} {most_common[0]}")
                    with col_stat4:
                        high_confidence = len([r for r in results if r['confidence'] > 0.7])
                        st.metric("D·ª± ƒëo√°n tin c·∫≠y cao", f"{high_confidence}/{len(results)}")

                    # Download results
                    st.markdown("#### üíæ T·∫£i k·∫øt qu·∫£")

                    # Prepare detailed results for download
                    detailed_results = []
                    for r in results:
                        row = {
                            'text': r['text'],
                            'predicted_emotion': r['emotion'],
                            'confidence': r['confidence']
                        }
                        # Add probability for each emotion
                        for emotion, prob in r['probabilities'].items():
                            row[f'prob_{emotion}'] = prob
                        detailed_results.append(row)

                    detailed_df = pd.DataFrame(detailed_results)

                    # Convert to CSV
                    csv = detailed_df.to_csv(index=False)
                    st.download_button(
                        label="üì• T·∫£i k·∫øt qu·∫£ (CSV)",
                        data=csv,
                        file_name=f"emotion_analysis_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )

                    # Store batch results for sidebar
                    st.session_state.batch_results = results

            elif text_input.strip():
                # Single text analysis
                with st.spinner("üîÑ ƒêang ph√¢n t√≠ch c·∫£m x√∫c..."):
                    result = predict_emotion(model, tokenizer, device, text_input)

                if result:
                    # Main prediction result
                    emotion = result['emotion']
                    confidence = result['confidence']
                    emoji = emotion_emojis[emotion]

                    st.markdown(f"""
                    <div class="prediction-box">
                        <h2>{emoji} {emotion}</h2>
                        <h3>ƒê·ªô tin c·∫≠y: {confidence:.2%}</h3>
                    </div>
                    """, unsafe_allow_html=True)

                    # Detailed results
                    st.markdown("### üìà Ph√¢n t√≠ch chi ti·∫øt")

                    # Probability chart
                    fig_bar = create_probability_chart(result['probabilities'])
                    st.plotly_chart(fig_bar, use_container_width=True)

                    # Probability table
                    prob_df = pd.DataFrame([
                        {
                            'C·∫£m x√∫c': emotion_emojis[emo] + " " + emo,
                            'X√°c su·∫•t': f"{prob:.4f}",
                            'Ph·∫ßn trƒÉm': f"{prob:.2%}"
                        }
                        for emo, prob in result['probabilities'].items()
                    ]).sort_values('Ph·∫ßn trƒÉm', ascending=False)

                    st.dataframe(
                        prob_df,
                        use_container_width=True,
                        hide_index=True
                    )

                    # Store result for sidebar
                    st.session_state.current_result = result
                    st.session_state.current_text = text_input

        elif predict_button and not text_input.strip() and not batch_analysis:
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n ho·∫∑c ch·ªçn t·ª´ file ƒë·ªÉ ph√¢n t√≠ch!")

    with col2:
        st.markdown("### üìä Th·ªëng k√™")

        # Text statistics
        if text_input.strip():
            st.markdown("#### üìù Th√¥ng tin vƒÉn b·∫£n")
            text_stats = {
                "S·ªë t·ª´": len(text_input.split()),
                "S·ªë k√Ω t·ª±": len(text_input),
                "S·ªë c√¢u": len([s for s in text_input.split('.') if s.strip()])
            }

            for stat, value in text_stats.items():
                st.metric(stat, value)

        # Batch analysis summary
        if hasattr(st.session_state, 'batch_results') and st.session_state.batch_results:
            st.markdown("#### üìä T√≥m t·∫Øt ph√¢n t√≠ch file")
            batch_results = st.session_state.batch_results

            # Quick stats
            total_analyzed = len(batch_results)
            avg_confidence = np.mean([r['confidence'] for r in batch_results])

            st.metric("ƒê√£ ph√¢n t√≠ch", f"{total_analyzed} vƒÉn b·∫£n")
            st.metric("ƒê·ªô tin c·∫≠y TB", f"{avg_confidence:.2%}")

            # Top emotions
            emotion_counts = {}
            for r in batch_results:
                emotion = r['emotion']
                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1

            st.markdown("**Top c·∫£m x√∫c:**")
            sorted_emotions = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)
            for emotion, count in sorted_emotions[:3]:
                percentage = (count / total_analyzed) * 100
                st.write(f"{emotion_emojis[emotion]} {emotion}: {count} ({percentage:.1f}%)")

        # History section
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []

        # Add to history when prediction is made
        if (hasattr(st.session_state, 'current_result') and
            hasattr(st.session_state, 'current_text')):

            # Check if this prediction is already in history
            current_time = datetime.now().strftime("%H:%M:%S")
            current_text_short = (st.session_state.current_text[:50] + "..."
                                if len(st.session_state.current_text) > 50
                                else st.session_state.current_text)

            # Add to history if not duplicate
            if (not st.session_state.prediction_history or
                st.session_state.prediction_history[-1]['text'] != current_text_short):

                st.session_state.prediction_history.append({
                    'time': current_time,
                    'text': current_text_short,
                    'emotion': st.session_state.current_result['emotion'],
                    'confidence': st.session_state.current_result['confidence']
                })

                # Keep only last 5 predictions
                if len(st.session_state.prediction_history) > 5:
                    st.session_state.prediction_history.pop(0)

        # Display history
        if st.session_state.prediction_history:
            st.markdown("#### üìö L·ªãch s·ª≠ ph√¢n t√≠ch")
            for i, pred in enumerate(reversed(st.session_state.prediction_history)):
                emoji = emotion_emojis[pred['emotion']]
                st.markdown(f"""
                <div class="emotion-card">
                    <small>{pred['time']}</small><br>
                    <strong>{emoji} {pred['emotion']}</strong> ({pred['confidence']:.2%})<br>
                    <em>"{pred['text']}"</em>
                </div>
                """, unsafe_allow_html=True)

            # Clear history button
            if st.button("üóëÔ∏è X√≥a l·ªãch s·ª≠", use_container_width=True):
                st.session_state.prediction_history = []
                st.rerun()

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: gray;">
        <p>üöÄ Ph√°t tri·ªÉn b·ªüi Nh√≥m AI - HVNH</p>
        <p>üìö S·ª≠ d·ª•ng m√¥ h√¨nh uitnlp/visobert v·ªõi Focal Loss</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()