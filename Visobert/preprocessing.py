import re, string


def normalText(sent):
    #Chuáº©n hÃ³a tiáº¿ng Viá»‡t, xá»­ lÃ½ emoj, chuáº©n hÃ³a tiáº¿ng Anh, thuáº­t ngá»¯
    replace_list = {
        'Ã²a': 'oÃ ', 'Ã³a': 'oÃ¡', 'á»a': 'oáº£', 'Ãµa': 'oÃ£', 'á»a': 'oáº¡', 'Ã²e': 'oÃ¨', 'Ã³e': 'oÃ©','á»e': 'oáº»',
        'Ãµe': 'oáº½', 'á»e': 'oáº¹', 'Ã¹y': 'uá»³', 'Ãºy': 'uÃ½', 'á»§y': 'uá»·', 'Å©y': 'uá»¹','á»¥y': 'uá»µ', 'uáº£': 'á»§a',
        'aÌ‰': 'áº£', 'Ã´Ì': 'á»‘', 'uÂ´': 'á»‘','Ã´Ìƒ': 'á»—', 'Ã´Ì€': 'á»“', 'Ã´Ì‰': 'á»•', 'Ã¢Ì': 'áº¥', 'Ã¢Ìƒ': 'áº«', 'Ã¢Ì‰': 'áº©',
        'Ã¢Ì€': 'áº§', 'oÌ‰': 'á»', 'ÃªÌ€': 'á»','ÃªÌƒ': 'á»…', 'ÄƒÌ': 'áº¯', 'uÌ‰': 'á»§', 'ÃªÌ': 'áº¿', 'Æ¡Ì‰': 'á»Ÿ', 'iÌ‰': 'á»‰',
        'eÌ‰': 'áº»', 'Ã k': u' Ã  ','aË‹': 'Ã ', 'iË‹': 'Ã¬', 'ÄƒÂ´': 'áº¯','Æ°Ì‰': 'á»­', 'eËœ': 'áº½', 'yËœ': 'á»¹', 'aÂ´': 'Ã¡',
        #Quy cÃ¡c icon 
        # VUI Váºº/THÃCH THÃš
        "ðŸ˜Š": "Vui váº»", "ðŸ˜": "Vui váº»", "ðŸ˜ƒ": "Vui váº»", "ðŸ˜„": "Vui váº»",
        "ðŸ˜†": "Vui váº»", "ðŸ¤£": "Vui váº»", "ðŸ˜¹": "Vui váº»", "ðŸ˜": "Vui váº»",
        "ðŸ˜˜": "Vui váº»", "ðŸ˜™": "Vui váº»", "ðŸ˜š": "Vui váº»", "ðŸ˜‹": "Vui váº»",
        "ðŸ˜›": "Vui váº»", "ðŸ˜œ": "Vui váº»", "ðŸ¤ª": "Vui váº»", "ðŸ¤—": "Vui váº»",
        "ðŸ˜Ž": "Vui váº»", "ðŸ™‚": "Vui váº»", "ðŸ’ƒ": "Vui váº»", "ðŸ•º": "Vui váº»",
        "ðŸ’–": "Vui váº»", "ðŸ’ž": "Vui váº»", "ðŸ’—": "Vui váº»", "ðŸ’•": "Vui váº»",
        "ðŸ’“": "Vui váº»", "â¤ï¸": "Vui váº»", "â¤": "Vui váº»", "â™¥": "Vui váº»",
        "ðŸ’œ": "Vui váº»", "ðŸ’™": "Vui váº»", "ðŸ’š": "Vui váº»", "ðŸ’›": "Vui váº»",
        "ðŸ’˜": "Vui váº»", "âœ¨": "Vui váº»", "ðŸŽ‰": "Vui váº»", "ðŸŒŸ": "Vui váº»",
        "ðŸŒ¸": "Vui váº»", "ðŸŒº": "Vui váº»", "ðŸŒ¼": "Vui váº»", "ðŸ˜‡": "Vui váº»",

        # BUá»’N BÃƒ
        "ðŸ˜¢": "Buá»“n bÃ£", "ðŸ˜­": "Buá»“n bÃ£", "ðŸ˜ž": "Buá»“n bÃ£", "ðŸ˜”": "Buá»“n bÃ£",
        "ðŸ˜Ÿ": "Buá»“n bÃ£", "ðŸ˜¿": "Buá»“n bÃ£", "ðŸ˜©": "Buá»“n bÃ£", "ðŸ˜«": "Buá»“n bÃ£",
        "ðŸ˜“": "Buá»“n bÃ£", "ðŸ˜¥": "Buá»“n bÃ£", "â˜¹": "Buá»“n bÃ£", "ðŸ™": "Buá»“n bÃ£",
        "ðŸ˜°": "Buá»“n bÃ£", "ðŸ˜ª": "Buá»“n bÃ£", "ðŸ˜•": "Buá»“n bÃ£",

        # Tá»¨C GIáº¬N
        "ðŸ˜¡": "Tá»©c giáº­n", "ðŸ˜ ": "Tá»©c giáº­n", "ðŸ¤¬": "Tá»©c giáº­n", "ðŸ‘¿": "Tá»©c giáº­n", "ðŸ’¢": "Tá»©c giáº­n",
        "ðŸ˜¤": "Tá»©c giáº­n", "ðŸ˜¾": "Tá»©c giáº­n", "ðŸš«": "Tá»©c giáº­n",

        # NGáº C NHIÃŠN
        "ðŸ˜²": "Ngáº¡c nhiÃªn", "ðŸ˜¯": "Ngáº¡c nhiÃªn", "ðŸ˜®": "Ngáº¡c nhiÃªn", "ðŸ˜³": "Ngáº¡c nhiÃªn",
        "ðŸ˜±": "Ngáº¡c nhiÃªn", "ðŸ¤¯": "Ngáº¡c nhiÃªn", "ðŸ˜µ": "Ngáº¡c nhiÃªn",

        # Sá»¢ HÃƒI
        "ðŸ˜¨": "Sá»£ hÃ£i", "ðŸ˜°": "Sá»£ hÃ£i", "ðŸ˜–": "Sá»£ hÃ£i", "ðŸ˜¬": "Sá»£ hÃ£i", "ðŸ˜§": "Sá»£ hÃ£i",
        "ðŸ˜·": "Sá»£ hÃ£i", "ðŸ‘»": "Sá»£ hÃ£i", "ðŸ˜±": "Sá»£ hÃ£i",

        # KINH Tá»žM
        "ðŸ¤¢": "Kinh tá»Ÿm", "ðŸ¤®": "Kinh tá»Ÿm", "ðŸ’©": "Kinh tá»Ÿm", "ðŸ˜’": "Kinh tá»Ÿm",
        "ðŸ˜‘": "Kinh tá»Ÿm", "ðŸ˜£": "Kinh tá»Ÿm", "ðŸ˜ ": "Kinh tá»Ÿm", "ðŸ‘Ž": "Kinh tá»Ÿm",

        # KHÃC
        "ðŸ¤”": "KhÃ¡c", "ðŸ˜": "KhÃ¡c", "ðŸ¤¨": "KhÃ¡c", "ðŸ˜¶": "KhÃ¡c",
        "ðŸ™ƒ": "KhÃ¡c", "ðŸ˜": "KhÃ¡c", "ðŸ§": "KhÃ¡c", "ðŸ˜Œ": "KhÃ¡c",
        "ðŸ’€": "KhÃ¡c", "ðŸ”¥": "KhÃ¡c", "?": "KhÃ¡c", "â€¦": "KhÃ¡c",


        #Chuáº©n hÃ³a 1 sá»‘ sentiment words/English words
        ':))': '  positive ', ':)': ' positive ', 'Ã´ kÃªi': ' ok ', 'okie': ' ok ', ' o kÃª ': ' ok ',
        'okey': ' ok ', 'Ã´kÃª': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okÃª':' ok ',
        ' tks ': u' cÃ¡m Æ¡n ', 'thks': u' cÃ¡m Æ¡n ', 'thanks': u' cÃ¡m Æ¡n ', 'ths': u' cÃ¡m Æ¡n ', 'thank': u' cÃ¡m Æ¡n ',
        'â­': 'star ', '*': 'star ', 'ðŸŒŸ': 'star ', 'ðŸŽ‰': u' positive ',
        'kg ': u' khÃ´ng ','not': u' khÃ´ng ', u' kg ': u' khÃ´ng ', '"k ': u' khÃ´ng ',' kh ':u' khÃ´ng ','kÃ´':u' khÃ´ng ','hok':u' khÃ´ng ',' kp ': u' khÃ´ng pháº£i ',u' kÃ´ ': u' khÃ´ng ', '"ko ': u' khÃ´ng ', u' ko ': u' khÃ´ng ', u' k ': u' khÃ´ng ', 'khong': u' khÃ´ng ', u' hok ': u' khÃ´ng ',
        'he he': ' positive ','hehe': ' positive ','hihi': ' positive ', 'haha': ' positive ', 'hjhj': ' positive ',
        ' lol ': ' negative ',' cc ': ' negative ','cute': u' dá»… thÆ°Æ¡ng ','huhu': ' negative ', ' vs ': u' vá»›i ', 'wa': ' quÃ¡ ', 'wÃ¡': u' quÃ¡', 'j': u' gÃ¬ ', 'â€œ': ' ',
        ' sz ': u' cá»¡ ', 'size': u' cá»¡ ', u' Ä‘x ': u' Ä‘Æ°á»£c ', 'dk': u' Ä‘Æ°á»£c ', 'dc': u' Ä‘Æ°á»£c ', 'Ä‘k': u' Ä‘Æ°á»£c ',
        'Ä‘c': u' Ä‘Æ°á»£c ','authentic': u' chuáº©n chÃ­nh hÃ£ng ',u' aut ': u' chuáº©n chÃ­nh hÃ£ng ', u' auth ': u' chuáº©n chÃ­nh hÃ£ng ', 'thick': u' positive ', 'store': u' cá»­a hÃ ng ',
        'shop': u' cá»­a hÃ ng ', 'sp': u' sáº£n pháº©m ', 'gud': u' tá»‘t ','god': u' tá»‘t ','wel done':' tá»‘t ', 'good': u' tá»‘t ', 'gÃºt': u' tá»‘t ',
        'sáº¥u': u' xáº¥u ','gut': u' tá»‘t ', u' tot ': u' tá»‘t ', u' nice ': u' tá»‘t ', 'perfect': 'ráº¥t tá»‘t', 'bt': u' bÃ¬nh thÆ°á»ng ',
        'time': u' thá»i gian ', 'qÃ¡': u' quÃ¡ ', u' ship ': u' giao hÃ ng ', u' m ': u' mÃ¬nh ', u' mik ': u' mÃ¬nh ',
        'ÃªÌ‰': 'á»ƒ', 'product': 'sáº£n pháº©m', 'quality': 'cháº¥t lÆ°á»£ng','chat':' cháº¥t ', 'excelent': 'hoÃ n háº£o', 'bad': 'tá»‡','fresh': ' tÆ°Æ¡i ','sad': ' tá»‡ ',
        'date': u' háº¡n sá»­ dá»¥ng ', 'hsd': u' háº¡n sá»­ dá»¥ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hÃ ng ',u' sÃ­p ': u' giao hÃ ng ',
        'beautiful': u' Ä‘áº¹p tuyá»‡t vá»i ', u' tl ': u' tráº£ lá»i ', u' r ': u' rá»“i ', u' shopE ': u' cá»­a hÃ ng ',u' order ': u' Ä‘áº·t hÃ ng ',
        'cháº¥t lg': u' cháº¥t lÆ°á»£ng ',u' sd ': u' sá»­ dá»¥ng ',u' dt ': u' Ä‘iá»‡n thoáº¡i ',u' nt ': u' nháº¯n tin ',u' tl ': u' tráº£ lá»i ',u' sÃ i ': u' xÃ i ',u'bjo':u' bao giá» ',
        'thik': u' thÃ­ch ',u' sop ': u' cá»­a hÃ ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' ráº¥t ',u'quáº£ ng ':u' quáº£ng  ',
        'dep': u' Ä‘áº¹p ',u' xau ': u' xáº¥u ','delicious': u' ngon ', u'hÃ g': u' hÃ ng ', u'qá»§a': u' quáº£ ',
        'iu': u' yÃªu ','fake': u' giáº£ máº¡o ', 'trl': 'tráº£ lá»i', '><': u' positive ',
        ' por ': u' tá»‡ ',' poor ': u' tá»‡ ', 'ib':u' nháº¯n tin ', 'rep':u' tráº£ lá»i ',u'fback':' feedback ','fedback':' feedback ',
        #dÆ°á»›i 3* quy vá» 1*, trÃªn 3* quy vá» 5*
        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',
        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',
        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}
    sent = sent.lower()
    for k, v in replace_list.items():
        sent = sent.replace(k, v)


    sent = str(sent).replace('_',' ').replace('/',' trÃªn ')
    sent = re.sub('-{2,}','',sent)
    sent = re.sub('\\s+',' ', sent)
    patPrice = r'([0-9]+k?(\s?-\s?)[0-9]+\s?(k|K))|([0-9]+(.|,)?[0-9]+\s?(triá»‡u|ngÃ n|trÄƒm|k|K|))|([0-9]+(.[0-9]+)?Ã„â€˜)|([0-9]+k)'
    patHagTag = r'#\s?[aÄƒÃ¢bcdÄ‘eÃªghiklmnoÃ´Æ¡pqrstuÆ°vxyÃ áº±áº§bcdÄ‘Ã¨á»ghÃ¬klmnÃ²á»“á»pqrstÃ¹á»«vxá»³Ã¡áº¯áº¥bcdÄ‘Ã©áº¿ghÃ­klmnÃ³á»‘á»›pqrstÃºá»©vxÃ½áº£áº³áº©bcdÄ‘áº»á»ƒghá»‰klmná»á»•á»Ÿpqrstá»§á»­vxá»·áº¡áº·áº­bcdÄ‘áº¹á»‡ghá»‹klmná»á»™á»£pqrstá»¥á»±vxá»µÃ£áºµáº«bcdÄ‘áº½á»…ghÄ©klmnÃµá»—á»¡pqrstÅ©á»¯vxá»¹AÄ‚Ã‚BCDÄEÃŠGHIKLMNOÃ”Æ PQRSTUÆ¯VXYÃ€áº°áº¦BCDÄÃˆá»€GHÃŒKLMNÃ’á»’á»œPQRSTÃ™á»ªVXá»²Ãáº®áº¤BCDÄÃ‰áº¾GHÃKLMNÃ“á»á»šPQRSTÃšá»¨VXÃáº áº¶áº¬BCDÄáº¸á»†GHá»ŠKLMNá»Œá»˜á»¢PQRSTá»¤á»°VXá»´áº¢áº²áº¨BCDÄáººá»‚GHá»ˆKLMNá»Žá»”á»žPQRSTá»¦á»¬VXá»¶Ãƒáº´áºªBCDÄáº¼á»„GHÄ¨KLMNÃ•á»–á» PQRSTÅ¨á»®VXá»¸]+'
    patURL = r"(?:http://|www.)[^\"]+"
    sent = re.sub(patURL,'website',sent)
    sent = re.sub(patHagTag,' hagtag ',sent)
    sent = re.sub(patPrice, ' giÃ¡ tiá»n ', sent)
    sent = re.sub(r'\.+','.',sent)
    sent = re.sub('(hagtag\\s+)+',' hagtag ',sent)
    sent = re.sub('\\s+',' ',sent)
    return sent

def deleteIcon(text):
    text = text.lower()
    s = ''
    pattern = r"[a-zA-ZaÄƒÃ¢bcdÄ‘eÃªghiklmnoÃ´Æ¡pqrstuÆ°vxyÃ áº±áº§bcdÄ‘Ã¨á»ghÃ¬klmnÃ²á»“á»pqrstÃ¹á»«vxá»³Ã¡áº¯áº¥bcdÄ‘Ã©áº¿ghÃ­klmnÃ³á»‘á»›pqrstÃºá»©vxÃ½áº£áº³áº©bcdÄ‘áº»á»ƒghá»‰klmná»á»•á»Ÿpqrstá»§á»­vxá»·áº¡áº·áº­bcdÄ‘áº¹á»‡ghá»‹klmná»á»™á»£pqrstá»¥á»±vxá»µÃ£áºµáº«bcdÄ‘áº½á»…ghÄ©klmnÃµá»—á»¡pqrstÅ©á»¯vxá»¹AÄ‚Ã‚BCDÄEÃŠGHIKLMNOÃ”Æ PQRSTUÆ¯VXYÃ€áº°áº¦BCDÄÃˆá»€GHÃŒKLMNÃ’á»’á»œPQRSTÃ™á»ªVXá»²Ãáº®áº¤BCDÄÃ‰áº¾GHÃKLMNÃ“á»á»šPQRSTÃšá»¨VXÃáº áº¶áº¬BCDÄáº¸á»†GHá»ŠKLMNá»Œá»˜á»¢PQRSTá»¤á»°VXá»´áº¢áº²áº¨BCDÄáººá»‚GHá»ˆKLMNá»Žá»”á»žPQRSTá»¦á»¬VXá»¶Ãƒáº´áºªBCDÄáº¼á»„GHÄ¨KLMNÃ•á»–á» PQRSTÅ¨á»®VXá»¸,._]"
    
    for char in text:
        if char !=' ':
            if len(re.findall(pattern, char)) != 0:
                s+=char
            elif char == '_':
                s+=char
        else:
            s+=char
    s = re.sub('\\s+',' ',s)
    return s.strip()

def normalize_elonge_word(sent):
    s_new = ''
    for word in sent.split(' '):
        word_new = ' '
        for char in word.strip():
            if char != word_new[-1]:
                word_new += char
        s_new += word_new.strip() + ' '
    return s_new.strip()

correct_mapping = {
    "ship": "váº­n chuyá»ƒn",
    "shop": "cá»­a hÃ ng",
    "m": "mÃ¬nh",
    "mik": "mÃ¬nh",
    "ko": "khÃ´ng",
    "k": " khÃ´ng ",
    "kh": "khÃ´ng",
    "khong": "khÃ´ng",
    "kg": "khÃ´ng",
    "khg": "khÃ´ng",
    "tl": "tráº£ lá»i",
    "r": "rá»“i",
    "fb": "máº¡ng xÃ£ há»™i", 
    "face": "máº¡ng xÃ£ há»™i",
    "thanks": "cáº£m Æ¡n",
    "thank": "cáº£m Æ¡n",
    "tks": "cáº£m Æ¡n",
    "tk": "cáº£m Æ¡n",
    "ok": "tá»‘t",
    "dc": "Ä‘Æ°á»£c",
    "vs": "vá»›i",
    "Ä‘t": "Ä‘iá»‡n thoáº¡i",
    "thjk": "thÃ­ch",
    "qÃ¡": "quÃ¡",
    "trá»ƒ": "trá»…",
    "bgjo": "bao giá»",
    "bÃ¹n": "buá»“n"
}
def tokmap(tok):
    if tok.lower() in correct_mapping:
        return correct_mapping[tok.lower()]
    else:
        return tok


def clean_doc(doc, lower_case=True, word_segment=True, max_length=256):
    if not doc:
        return ""
    #  Chuáº©n hÃ³a vÄƒn báº£n 
    doc = normalText(doc)

    # ChÃ¨n khoáº£ng tráº¯ng quanh dáº¥u "?" Ä‘á»ƒ tokenizer xá»­ lÃ½ dá»… hÆ¡n
    doc = re.sub(r"\?", r" ? ", doc)

    # Thay tháº¿ sá»‘ báº±ng token "sá»‘"
    doc = re.sub(r"[0-9]+", " sá»‘ ", doc)

    # Chuáº©n hÃ³a khoáº£ng tráº¯ng
    doc = re.sub(r"\s+", " ", doc)

    # Chuáº©n hÃ³a cÃ¡c tá»« bá»‹ kÃ©o dÃ i (vd: "Ä‘áº¹ppppp" â†’ "Ä‘áº¹p")
    doc = normalize_elonge_word(doc)

    # Xá»­ lÃ½ tá»« Ä‘áº·c biá»‡t "giÃ¡ tiá»n"
    if word_segment:
        doc = doc.replace("giÃ¡ _ tiá»n", "giÃ¡_tiá»n").replace("giÃ¡tiá»n", "giÃ¡_tiá»n")
    else:
        doc = doc.replace("giÃ¡ _ tiá»n", "giÃ¡ tiá»n").replace("giÃ¡tiá»n", "giÃ¡ tiá»n")

    # Chuáº©n hÃ³a khoáº£ng tráº¯ng láº§n ná»¯a
    doc = re.sub(r"\s+", " ", doc).strip()

    # Map tá»«ng token
    tokens = map(tokmap, doc.split())
    doc = " ".join(tokens)

    # Náº¿u chuá»—i quÃ¡ dÃ i, giá»¯ láº¡i Ä‘áº§u + cuá»‘i (cáº¯t giá»¯a)
    array = doc.split()
    if len(array) > max_length:
        half = max_length // 2
        doc = " ".join(array[:half] + array[-half:])

    # 12. Thay tháº¿ má»™t sá»‘ máº«u Ä‘áº·c biá»‡t
    doc = doc.replace(". . .", ".")

    return re.sub(r"\s+", " ", doc).strip()
