import os
import sys

# Add project root to Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
sys.path.append(project_root)

import streamlit as st
import pickle
import re
import pandas as pd
import numpy as np
import torch
from transformers import AutoTokenizer
import matplotlib.pyplot as plt
import seaborn as sns

# Now we can import from src
from src.models.LSTM_AttentionClassifier import LSTM_AttentionClassifier 
from config.config import get_config
from src.preprocess.preprocess_data import clean_doc

# Verify project structure
def verify_project_structure():
    required_paths = {
        'models_dir': os.path.join(project_root, 'outputs', 'models'),
        'model_file': os.path.join(project_root, 'outputs', 'models', 'best_model.pt'),
    }
    
    missing = []
    for name, path in required_paths.items():
        if not os.path.exists(path):
            missing.append(f"{name}: {path}")
    
    if missing:
        st.error("Missing required files/directories:")
        for m in missing:
            st.error(m)
        return False
    return True

# Set page config
st.set_page_config(
    page_title="Ph√¢n t√≠ch C·∫£m x√∫c Ti·∫øng Vi·ªát",
    page_icon="‚ù§Ô∏è",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .main {
        padding: 20px;
    }
    .title {
        color: #2e4d7b;
        text-align: center;
    }
    .stTextArea {
        margin-bottom: 20px;
    }
    .prediction {
        padding: 20px;
        border-radius: 5px;
        margin: 10px 0;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_model():
    try:
        if not verify_project_structure():
            return None, None, None, None
            
        config = get_config()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # Load tokenizer
        tokenizer = AutoTokenizer.from_pretrained("vinai/phobert-base", use_fast=False)
        
        # Initialize model
        model = LSTM_AttentionClassifier(
            vocab_size=tokenizer.vocab_size,
            embed_dim=config.model.embed_dim,
            hidden_dim=config.model.hidden_dim,
            num_classes=len(config.emotion_labels),
            num_layers=config.model.num_layers,
            n_heads=config.model.n_heads,
            dropout=0.1
        ).to(device)
        
        # Load model weights
        model_path = os.path.join(project_root, 'outputs', 'models', 'best_model.pt')
        model.load_state_dict(torch.load(model_path, map_location=device))
        model.eval()
        
        return model, tokenizer, device, config
    except Exception as e:
        st.error(f"Error loading model: {str(e)}")
        return None, None, None, None

def predict_emotion(text, model, tokenizer, device, config):
    try:
        # Preprocess using clean_doc
        processed_text = clean_doc(
            doc=text,
            word_segment=True,
            lower_case=True,
            max_length=config.data.max_len
        )
        
        # Tokenize
        encoding = tokenizer(
            processed_text,
            padding=True,
            truncation=True,
            max_length=config.data.max_len,
            return_tensors='pt'
        )
        
        # Predict
        with torch.no_grad():
            input_ids = encoding['input_ids'].to(device)
            attention_mask = encoding['attention_mask'].to(device)
            lengths = attention_mask.sum(1)
            
            logits = model(input_ids, lengths)
            probs = torch.softmax(logits, dim=1)
            prediction = torch.argmax(logits, dim=1)
            
        return config.emotion_labels[prediction.item()], probs[0].cpu().numpy()
    except Exception as e:
        st.error(f"Error during prediction: {str(e)}")
        return None, None

def main():
    st.title("üé≠ Ph√¢n t√≠ch C·∫£m x√∫c VƒÉn b·∫£n Ti·∫øng Vi·ªát")
    
    # Load model
    model, tokenizer, device, config = load_model()
    if model is None:
        st.error("Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh. Vui l√≤ng th·ª≠ l·∫°i sau.")
        return
        
    # Tabs
    tab1, tab2 = st.tabs(["Nh·∫≠p vƒÉn b·∫£n", "T·∫£i file"])
    
    # Tab 1: Text Input
    with tab1:
        user_input = st.text_area(
            "Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:",
            height=150,
            placeholder="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát v√†o ƒë√¢y..."
        )
        
        col1, col2, col3 = st.columns([1,1,1])
        with col2:
            analyze_button = st.button("üîç Ph√¢n t√≠ch", use_container_width=True)
            
        if analyze_button and user_input:
            with st.spinner('ƒêang ph√¢n t√≠ch...'):
                emotion, probabilities = predict_emotion(user_input, model, tokenizer, device, config)
                
                if emotion and probabilities is not None:
                    # Map emotions to Vietnamese
                    emotion_map = {
                        'Enjoyment': 'Vui v·∫ª',
                        'Sadness': 'Bu·ªìn b√£', 
                        'Anger': 'T·ª©c gi·∫≠n',
                        'Surprise': 'Ng·∫°c nhi√™n',
                        'Fear': 'S·ª£ h√£i',
                        'Disgust': 'Gh√™ t·ªüm',
                        'Other': 'Kh√°c'
                    }
                    
                    # Display results
                    # Hi·ªÉn th·ªã vƒÉn b·∫£n ƒë√£ nh·∫≠p sau khi ti·ªÅn x·ª≠ l√Ω
                    st.markdown(f"**VƒÉn b·∫£n ƒë√£ nh·∫≠p:** {user_input}")
                    st.markdown(f"**VƒÉn b·∫£n ƒë√£ ti·ªÅn x·ª≠ l√Ω:** {clean_doc(user_input, word_segment=True, lower_case=True, max_length=config.data.max_len)}")
                    st.markdown("**C·∫£m x√∫c d·ª± ƒëo√°n:**")
                    # Display emotion in Vietnamese
                    st.success(f"### K·∫øt qu·∫£: {emotion_map.get(emotion, emotion)}")
                    
                    # Display probability distribution
                    prob_df = pd.DataFrame({
                        'C·∫£m x√∫c': [emotion_map.get(label, label) for label in config.emotion_labels],
                        'X√°c su·∫•t': probabilities
                    })
                    st.bar_chart(prob_df.set_index('C·∫£m x√∫c'))
    
    # Tab 2: File Upload 
    with tab2:
        uploaded_file = st.file_uploader("Ch·ªçn file Excel/CSV", type=['csv', 'xlsx'])
        if uploaded_file:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                if 'Sentence' not in df.columns:
                    st.error("File ph·∫£i c√≥ c·ªôt 'Sentence' ch·ª©a vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch")
                    return
                
                if st.button("Ph√¢n t√≠ch file"):
                    progress_bar = st.progress(0)
                    results = []
                    probabilities_list = []
                    
                    for i, text in enumerate(df['Sentence']):
                        emotion, probs = predict_emotion(text, model, tokenizer, device, config)
                        results.append(emotion)
                        probabilities_list.append(probs)
                        progress_bar.progress((i + 1) / len(df))
                    
                    df['predicted_emotion'] = results
                    
                    # Convert predictions to Vietnamese
                    emotion_map = {
                        'Enjoyment': 'Vui v·∫ª',
                        'Sadness': 'Bu·ªìn b√£', 
                        'Anger': 'T·ª©c gi·∫≠n',
                        'Surprise': 'Ng·∫°c nhi√™n',
                        'Fear': 'S·ª£ h√£i',
                        'Disgust': 'Gh√™ t·ªüm',
                        'Other': 'Kh√°c'
                    }
                    df['predicted_emotion_vi'] = df['predicted_emotion'].map(emotion_map)

                    st.success("Ph√¢n t√≠ch ho√†n t·∫•t!")
                    
                    # Display results in tabs
                    result_tab1, result_tab2 = st.tabs(["K·∫øt qu·∫£ chi ti·∫øt", "Th·ªëng k√™"])
                    
                    with result_tab1:
                        st.dataframe(df)
                        
                        # Download results button
                        st.download_button(
                            "üì• T·∫£i k·∫øt qu·∫£",
                            df.to_csv(index=False).encode('utf-8'),
                            "results.csv",
                            "text/csv",
                            key='download-csv'
                        )
                    
                    with result_tab2:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            # Pie chart for emotion distribution
                            emotion_counts = df['predicted_emotion_vi'].value_counts()
                            fig_pie = plt.figure(figsize=(10, 6))
                            plt.pie(emotion_counts.values, 
                                  labels=emotion_counts.index, 
                                  autopct='%1.1f%%',
                                  colors=sns.color_palette('Set3'))
                            plt.title('Ph√¢n b·ªë c·∫£m x√∫c')
                            st.pyplot(fig_pie)
                        
                        with col2:
                            # Bar chart for emotion counts
                            fig_bar = plt.figure(figsize=(10, 6))
                            sns.barplot(x=emotion_counts.values, 
                                      y=emotion_counts.index,
                                      palette='Set3')
                            plt.title('S·ªë l∆∞·ª£ng m·ªói c·∫£m x√∫c')
                            plt.xlabel('S·ªë l∆∞·ª£ng')
                            st.pyplot(fig_bar)


            except Exception as e:
                st.error(f"L·ªói khi x·ª≠ l√Ω file: {str(e)}")

if __name__ == "__main__":
    main()
